{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, Spark SQL is used instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) import libraries you might need\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg\n",
    "# from pyspark.sql.functions import sum as Fsum\n",
    "# from pyspark.sql.window import Window\n",
    "# from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) instantiate a Spark session\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark SQL Quiz\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(\"data/sparkify_log_small.json\")\n",
    "\n",
    "# 4) create a view to use with your SQL queries\n",
    "user_log.createOrReplaceTempView(\"log_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|page|            page|\n",
      "+----+----------------+\n",
      "|null|Submit Downgrade|\n",
      "|null|       Downgrade|\n",
      "|null|          Logout|\n",
      "|null|   Save Settings|\n",
      "|null|        Settings|\n",
      "|null|        NextSong|\n",
      "|null|         Upgrade|\n",
      "|null|           Error|\n",
      "|null|  Submit Upgrade|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT distinct pages for the blank user and distinc pages for all users\n",
    "# Right join the results to find pages that blank visitor did not visit\n",
    "\n",
    "spark.sql(\"SELECT * \\\n",
    "            FROM ( \\\n",
    "                SELECT DISTINCT page \\\n",
    "                FROM log_table \\\n",
    "                WHERE userId = '') AS user_pages \\\n",
    "            RIGHT JOIN ( \\\n",
    "                SELECT DISTINCT page \\\n",
    "                FROM log_table) AS all_pages \\\n",
    "            ON user_pages.page = all_pages.page \\\n",
    "            WHERE user_pages.page IS NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Both Spark SQL and Spark Data Frames are part of the Spark SQL library. Hence, they both use the Spark SQL Catalyst Optimizer to optimize queries.\n",
    "\n",
    "You might prefer SQL over data frames because the syntax is clearer especially for teams already experienced in SQL.\n",
    "\n",
    "Spark data frames give you more control. You can break down your queries into smaller steps, which can make debugging easier. You can also cache intermediate results or repartition intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                   462|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "\n",
    "spark.sql(\"SELECT COUNT(DISTINCT userId) \\\n",
    "            FROM log_table \\\n",
    "            WHERE gender = 'F'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Artist|plays|\n",
      "+--------+-----+\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "\n",
    "spark.sql(\"SELECT Artist, count(Artist) As plays \\\n",
    "            FROM log_table \\\n",
    "            GROUP BY Artist \\\n",
    "            ORDER BY plays DESC \\\n",
    "            LIMIT 1\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+\n",
      "|userID|    page|           ts|is_home|\n",
      "+------+--------+-------------+-------+\n",
      "|  1046|NextSong|1513720872284|      0|\n",
      "|  1000|NextSong|1513720878284|      0|\n",
      "|  2219|NextSong|1513720881284|      0|\n",
      "|  2373|NextSong|1513720905284|      0|\n",
      "|  1747|    Home|1513720913284|      1|\n",
      "|  1162|NextSong|1513720955284|      0|\n",
      "|  1061|NextSong|1513720959284|      0|\n",
      "|   748|    Home|1513720959284|      1|\n",
      "|   597|    Home|1513720980284|      1|\n",
      "|  1806|NextSong|1513720983284|      0|\n",
      "|   748|NextSong|1513720993284|      0|\n",
      "|  1176|NextSong|1513721031284|      0|\n",
      "|  2164|NextSong|1513721045284|      0|\n",
      "|  2146|NextSong|1513721058284|      0|\n",
      "|  2219|NextSong|1513721077284|      0|\n",
      "|  1176|    Home|1513721088284|      1|\n",
      "|  2904|NextSong|1513721095284|      0|\n",
      "|   597|NextSong|1513721097284|      0|\n",
      "|   226|NextSong|1513721104284|      0|\n",
      "|  1046|NextSong|1513721104284|      0|\n",
      "+------+--------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT CASE WHEN 1 > 0 THEN 1 WHEN 2 > 0 THEN 2.0 ELSE 1.2 END;\n",
    "is_home = spark.sql(\"SELECT userID, page, ts, CASE WHEN page = 'Home' THEN 1 ELSE 0 END as is_home FROM log_table \\\n",
    "                WHERE (page = 'NextSong') or (page = 'Home') \\\n",
    "                \")\n",
    "\n",
    "# keep the results in a new view\n",
    "is_home.createOrReplaceTempView(\"is_home_table\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM is_home_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+------+\n",
      "|userID|    page|           ts|is_home|period|\n",
      "+------+--------+-------------+-------+------+\n",
      "|  1436|NextSong|1513783259284|      0|     0|\n",
      "|  1436|NextSong|1513782858284|      0|     0|\n",
      "|  2088|    Home|1513805972284|      1|     1|\n",
      "|  2088|NextSong|1513805859284|      0|     1|\n",
      "|  2088|NextSong|1513805494284|      0|     1|\n",
      "|  2088|NextSong|1513805065284|      0|     1|\n",
      "|  2088|NextSong|1513804786284|      0|     1|\n",
      "|  2088|NextSong|1513804555284|      0|     1|\n",
      "|  2088|NextSong|1513804196284|      0|     1|\n",
      "|  2088|NextSong|1513803967284|      0|     1|\n",
      "|  2088|NextSong|1513803820284|      0|     1|\n",
      "|  2088|NextSong|1513803651284|      0|     1|\n",
      "|  2088|NextSong|1513803413284|      0|     1|\n",
      "|  2088|NextSong|1513803254284|      0|     1|\n",
      "|  2088|NextSong|1513803057284|      0|     1|\n",
      "|  2088|NextSong|1513802824284|      0|     1|\n",
      "|  2162|NextSong|1513781246284|      0|     0|\n",
      "|  2162|NextSong|1513781065284|      0|     0|\n",
      "|  2162|NextSong|1513780860284|      0|     0|\n",
      "|  2162|NextSong|1513780569284|      0|     0|\n",
      "+------+--------+-------------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql(\"SELECT *, SUM(is_home) OVER \\\n",
    "    (PARTITION BY userID ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period \\\n",
    "    FROM is_home_table\")\n",
    "\n",
    "# keep the results in a view\n",
    "cumulative_sum.createOrReplaceTempView(\"period_table\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM period_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the average count for NextSong\n",
    "\n",
    "spark.sql(\"SELECT AVG(count_results) FROM \\\n",
    "         (SELECT COUNT(*) AS count_results FROM period_table \\\n",
    "        GROUP BY userID, period, page HAVING page = 'NextSong') AS counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
